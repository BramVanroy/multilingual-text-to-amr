{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-14T15:26:21.246380928Z",
     "start_time": "2023-09-14T15:26:21.205274540Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = json.loads(Path(\"../data/preprocessed/amr30-es_nl-fixed_no_processing_stratified/corpus_statistics.json\").read_text(encoding=\"utf-8\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T15:26:21.271954763Z",
     "start_time": "2023-09-14T15:26:21.246809264Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET INFO\n",
      "============\n",
      "*** TEST ***\n",
      "No. samples: 1,898\n",
      "Longest sequence of white-spaced tokens: 175\n",
      "*** TRAIN ***\n",
      "No. samples: 55,635\n",
      "Longest sequence of white-spaced tokens: 246\n",
      "*** VALIDATION ***\n",
      "No. samples: 1,722\n",
      "Longest sequence of white-spaced tokens: 123\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_info = data.pop(\"dataset\")\n",
    "print(\"DATASET INFO\\n============\")\n",
    "dataset_lengths = []\n",
    "for split_type, split_data in dataset_info.items():\n",
    "    print(f\"*** {split_type.upper()} ***\")\n",
    "    print(f\"No. samples: {split_data['num_samples']:,}\")\n",
    "    print(f\"Longest sequence of white-spaced tokens: {split_data['max_num_ws_tokens']:,}\")\n",
    "    dataset_lengths = [{\"split_type\": split_type, \"num_ws_tokens\": num_ws_tokens} for num_ws_tokens in split_data[\"num_ws_tokens\"]]\n",
    "    dataset_lengths = pd.DataFrame(dataset_lengths)\n",
    "    # sns.displot(dataset_lengths, x=\"num_ws_tokens\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T15:26:21.402708091Z",
     "start_time": "2023-09-14T15:26:21.381550222Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df_data = []\n",
    "for tokenizer_name, splitsd in data.items():\n",
    "    max_length = splitsd.pop(\"max_length\")\n",
    "    for split_type, stats in splitsd.items():\n",
    "        df_data.append({\n",
    "            \"tokenizer\": tokenizer_name,\n",
    "            \"max_length\": max_length,\n",
    "            \"split_type\": split_type,\n",
    "            **stats\n",
    "        })\n",
    "df = pd.DataFrame(df_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T15:26:21.406796870Z",
     "start_time": "2023-09-14T15:26:21.404582827Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                                  tokenizer  max_length  split_type  \\\n0                    bigscience/bloomz-560m        2048        test   \n1                    bigscience/bloomz-560m        2048       train   \n2                    bigscience/bloomz-560m        2048  validation   \n3                 facebook/mbart-large-cc25        1024        test   \n4                 facebook/mbart-large-cc25        1024       train   \n5                 facebook/mbart-large-cc25        1024  validation   \n6   facebook/mbart-large-50-many-to-one-mmt        1024        test   \n7   facebook/mbart-large-50-many-to-one-mmt        1024       train   \n8   facebook/mbart-large-50-many-to-one-mmt        1024  validation   \n9                           google/mt5-base        1024        test   \n10                          google/mt5-base        1024       train   \n11                          google/mt5-base        1024  validation   \n12                                  t5-base         512        test   \n13                                  t5-base         512       train   \n14                                  t5-base         512  validation   \n15                   facebook/nllb-200-3.3B        1024        test   \n16                   facebook/nllb-200-3.3B        1024       train   \n17                   facebook/nllb-200-3.3B        1024  validation   \n18                      google/flan-t5-base         512        test   \n19                      google/flan-t5-base         512       train   \n20                      google/flan-t5-base         512  validation   \n\n    max_subwordtok_len_sents  \\\n0                        393   \n1                        494   \n2                        249   \n3                        323   \n4                        346   \n5                        189   \n6                        323   \n7                        346   \n8                        189   \n9                        338   \n10                       412   \n11                       214   \n12                       542   \n13                       688   \n14                       358   \n15                       326   \n16                       359   \n17                       198   \n18                       542   \n19                       688   \n20                       358   \n\n                                subwordtok_lens_sents  num_sent_gt_maxlength  \\\n0   [1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, ...                      0   \n1   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                      0   \n2   [1, 1, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...                      0   \n3   [3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, ...                      0   \n4   [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...                      0   \n5   [3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, ...                      0   \n6   [3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, ...                      0   \n7   [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...                      0   \n8   [3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, ...                      0   \n9   [2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...                      0   \n10  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...                      0   \n11  [2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...                      0   \n12  [3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...                      1   \n13  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...                      1   \n14  [2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...                      0   \n15  [3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, ...                      0   \n16  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...                      0   \n17  [3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, ...                      0   \n18  [3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...                      1   \n19  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...                      1   \n20  [2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...                      0   \n\n    max_subwordtok_len_labels  \\\n0                         835   \n1                         824   \n2                         529   \n3                         857   \n4                         842   \n5                         543   \n6                         857   \n7                         842   \n8                         543   \n9                         846   \n10                        833   \n11                        537   \n12                        512   \n13                        512   \n14                        512   \n15                        851   \n16                        846   \n17                        542   \n18                        512   \n19                        512   \n20                        512   \n\n                               subwordtok_lens_labels  num_lbl_gt_maxlength  \n0   [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 6, 8, 8, 9, ...                     0  \n1   [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...                     0  \n2   [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...                     0  \n3   [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 9, 9, 11, 11...                     0  \n4   [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...                     0  \n5   [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...                     0  \n6   [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 9, 9, 11, 11...                     0  \n7   [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...                     0  \n8   [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...                     0  \n9   [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 8, 9, 9, ...                     0  \n10  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...                     0  \n11  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...                     0  \n12  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 8, 9, 9, ...                     0  \n13  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...                     0  \n14  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...                     0  \n15  [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 8, 9, 10, 10...                     0  \n16  [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...                     0  \n17  [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...                     0  \n18  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 8, 9, 9, ...                     0  \n19  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...                     0  \n20  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...                     0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokenizer</th>\n      <th>max_length</th>\n      <th>split_type</th>\n      <th>max_subwordtok_len_sents</th>\n      <th>subwordtok_lens_sents</th>\n      <th>num_sent_gt_maxlength</th>\n      <th>max_subwordtok_len_labels</th>\n      <th>subwordtok_lens_labels</th>\n      <th>num_lbl_gt_maxlength</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bigscience/bloomz-560m</td>\n      <td>2048</td>\n      <td>test</td>\n      <td>393</td>\n      <td>[1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, ...</td>\n      <td>0</td>\n      <td>835</td>\n      <td>[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 6, 8, 8, 9, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bigscience/bloomz-560m</td>\n      <td>2048</td>\n      <td>train</td>\n      <td>494</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n      <td>0</td>\n      <td>824</td>\n      <td>[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bigscience/bloomz-560m</td>\n      <td>2048</td>\n      <td>validation</td>\n      <td>249</td>\n      <td>[1, 1, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n      <td>0</td>\n      <td>529</td>\n      <td>[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>facebook/mbart-large-cc25</td>\n      <td>1024</td>\n      <td>test</td>\n      <td>323</td>\n      <td>[3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, ...</td>\n      <td>0</td>\n      <td>857</td>\n      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 9, 9, 11, 11...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>facebook/mbart-large-cc25</td>\n      <td>1024</td>\n      <td>train</td>\n      <td>346</td>\n      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n      <td>0</td>\n      <td>842</td>\n      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>facebook/mbart-large-cc25</td>\n      <td>1024</td>\n      <td>validation</td>\n      <td>189</td>\n      <td>[3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, ...</td>\n      <td>0</td>\n      <td>543</td>\n      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>facebook/mbart-large-50-many-to-one-mmt</td>\n      <td>1024</td>\n      <td>test</td>\n      <td>323</td>\n      <td>[3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, ...</td>\n      <td>0</td>\n      <td>857</td>\n      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 9, 9, 11, 11...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>facebook/mbart-large-50-many-to-one-mmt</td>\n      <td>1024</td>\n      <td>train</td>\n      <td>346</td>\n      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n      <td>0</td>\n      <td>842</td>\n      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>facebook/mbart-large-50-many-to-one-mmt</td>\n      <td>1024</td>\n      <td>validation</td>\n      <td>189</td>\n      <td>[3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, ...</td>\n      <td>0</td>\n      <td>543</td>\n      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>google/mt5-base</td>\n      <td>1024</td>\n      <td>test</td>\n      <td>338</td>\n      <td>[2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n      <td>0</td>\n      <td>846</td>\n      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 8, 9, 9, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>google/mt5-base</td>\n      <td>1024</td>\n      <td>train</td>\n      <td>412</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>0</td>\n      <td>833</td>\n      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>google/mt5-base</td>\n      <td>1024</td>\n      <td>validation</td>\n      <td>214</td>\n      <td>[2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n      <td>0</td>\n      <td>537</td>\n      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>t5-base</td>\n      <td>512</td>\n      <td>test</td>\n      <td>542</td>\n      <td>[3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...</td>\n      <td>1</td>\n      <td>512</td>\n      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 8, 9, 9, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>t5-base</td>\n      <td>512</td>\n      <td>train</td>\n      <td>688</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>1</td>\n      <td>512</td>\n      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>t5-base</td>\n      <td>512</td>\n      <td>validation</td>\n      <td>358</td>\n      <td>[2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...</td>\n      <td>0</td>\n      <td>512</td>\n      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>facebook/nllb-200-3.3B</td>\n      <td>1024</td>\n      <td>test</td>\n      <td>326</td>\n      <td>[3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n      <td>0</td>\n      <td>851</td>\n      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 8, 9, 10, 10...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>facebook/nllb-200-3.3B</td>\n      <td>1024</td>\n      <td>train</td>\n      <td>359</td>\n      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n      <td>0</td>\n      <td>846</td>\n      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>facebook/nllb-200-3.3B</td>\n      <td>1024</td>\n      <td>validation</td>\n      <td>198</td>\n      <td>[3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n      <td>0</td>\n      <td>542</td>\n      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>google/flan-t5-base</td>\n      <td>512</td>\n      <td>test</td>\n      <td>542</td>\n      <td>[3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...</td>\n      <td>1</td>\n      <td>512</td>\n      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 8, 9, 9, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>google/flan-t5-base</td>\n      <td>512</td>\n      <td>train</td>\n      <td>688</td>\n      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>1</td>\n      <td>512</td>\n      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>google/flan-t5-base</td>\n      <td>512</td>\n      <td>validation</td>\n      <td>358</td>\n      <td>[2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...</td>\n      <td>0</td>\n      <td>512</td>\n      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T15:26:21.477344525Z",
     "start_time": "2023-09-14T15:26:21.407081598Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigscience/bloomz-560m test 393 108.02999999999997 78.0 835 282.1199999999999 207.0\n",
      "bigscience/bloomz-560m train 494 99.0 68.0 824 251.0 177.0\n",
      "bigscience/bloomz-560m validation 249 102.0 74.0 529 266.0 204.0\n",
      "facebook/mbart-large-cc25 test 323 90.02999999999997 70.0 857 287.03 214.14999999999986\n",
      "facebook/mbart-large-cc25 train 346 88.0 61.0 842 257.0 182.0\n",
      "facebook/mbart-large-cc25 validation 189 88.0 65.0 543 272.0 210.0\n",
      "facebook/mbart-large-50-many-to-one-mmt test 323 90.02999999999997 70.0 857 287.03 214.14999999999986\n",
      "facebook/mbart-large-50-many-to-one-mmt train 346 88.0 61.0 842 257.0 182.0\n",
      "facebook/mbart-large-50-many-to-one-mmt validation 189 88.0 65.0 543 272.0 210.0\n",
      "google/mt5-base test 338 101.02999999999997 78.0 846 289.03 212.0\n",
      "google/mt5-base train 412 98.0 69.0 833 255.0 181.0\n",
      "google/mt5-base validation 214 101.78999999999996 75.0 537 272.0 208.0\n",
      "t5-base test 542 167.05999999999995 124.0 512 297.0 215.14999999999986\n",
      "t5-base train 688 155.0 109.0 512 257.0 182.0\n",
      "t5-base validation 358 155.57999999999993 118.0 512 273.78999999999996 209.94999999999982\n",
      "facebook/nllb-200-3.3B test 326 92.05999999999995 72.0 851 293.05999999999995 213.29999999999973\n",
      "facebook/nllb-200-3.3B train 359 90.0 63.0 846 257.0 182.0\n",
      "facebook/nllb-200-3.3B validation 198 88.0 67.0 542 273.0 209.0\n",
      "google/flan-t5-base test 542 167.05999999999995 124.0 512 297.0 215.14999999999986\n",
      "google/flan-t5-base train 688 155.0 109.0 512 257.0 182.0\n",
      "google/flan-t5-base validation 358 155.57999999999993 118.0 512 273.78999999999996 209.94999999999982\n"
     ]
    },
    {
     "data": {
      "text/plain": "0     None\n1     None\n2     None\n3     None\n4     None\n5     None\n6     None\n7     None\n8     None\n9     None\n10    None\n11    None\n12    None\n13    None\n14    None\n15    None\n16    None\n17    None\n18    None\n19    None\n20    None\ndtype: object"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def print_stats(row):\n",
    "    max_sents = max(row[\"subwordtok_lens_sents\"])\n",
    "    q99_sents = np.percentile(row[\"subwordtok_lens_sents\"], 99)\n",
    "    q95_sents = np.percentile(row[\"subwordtok_lens_sents\"], 95)\n",
    "    max_lbls = max(row[\"subwordtok_lens_labels\"])\n",
    "    q99_lbls = np.percentile(row[\"subwordtok_lens_labels\"], 99)\n",
    "    q95_lbls = np.percentile(row[\"subwordtok_lens_labels\"], 95)\n",
    "    tokenizer_name = row[\"tokenizer\"]\n",
    "    split_type = row[\"split_type\"]\n",
    "    print(tokenizer_name, split_type, max_sents, q99_sents, q95_sents, max_lbls, q99_lbls, q95_lbls)\n",
    "\n",
    "df.apply(print_stats, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T15:26:21.531632543Z",
     "start_time": "2023-09-14T15:26:21.477565113Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
